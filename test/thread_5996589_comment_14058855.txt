Thread ID: 5996589
User 134876 (Original Post) says:
As a supplementary explanation, I'd like to provide some intuition about Multi-Dimensional Scaling (MDS), which is the foundation of the ISOMAP. 

1. The motivation of MDS, to find a low-dimensional representation (so-called embedding), is for visualization purposes. There is a family of MDS algorithms. We focus on the Classic-MDS (cMDS in some literature) in our class. (We will refer to cMDS as MDS in the following.)

2. We have a set of $m$ data points, $y_1, \cdots, y_m$, where $ y_i \in \mathbb R^d$. We also have a distance measure (dissimilarity function) $d(y_i, y_j)$. Such distance measure is the core interest for the raw feature data in many real-world problems, and it is usually based on prior knowledge (or presumptions). 

3. We want to have a low-dimensional representation of the data (this is an approximation in general). The objective of MDS is to find such embedding $y \rightarrow z: \mathbb R^d \rightarrow \mathbb R^k$, where $k$ is our desired embedding dimension. (In our course example, $ k =2$)

4. Note that the raw data $y_i$ will not join the subsequent MDS procedure. Only the pair-wise distance $d_{i,j} = d(y_i, y_j)$ are involved. Denote the m-by-m dissimilarity matrix as $D(i,j) = d_{i,j}$.

5. Based on the given dissimilarity matrix $D$, we move on to finding the embedding $z$. The MDS finds the embedding $z$ by treating the dissimilarity matrix $D$ as Euclidean (Note such treatment is why we say the MDS result is an approximation. I will explain further in the last section.) In this case, we can utilize the equation on lecture slides p14:

$$d^2_{i,j} = \|z_i - z_j\|^2$$

In matrix form:

$$(D)^2 = a \mathbb I^T + \mathbb I a^T - 2 Z^T Z$$

where $\mathbb I$ is the all-one vector.

(keep in mind, $D$ is known, $Z$ is the unknown to be found)

6. Now the issue is, that the above equation does not have a unique solution. The reason can be seen quite straightforward with the intuition: $\|z_i - z_j\|$ is the distance between the two embeddings in the space, and if we shift all $z_i$ to an arbitrary location in the embedding space, the distance remains unchanged. Therefore, we need to add an additional constraint by centering the embeddings, thus it can achieve a unique solution. This centering operation corresponds to $H = I - \frac1m \mathbb I \mathbb I^T$ in our lecture slides p16.

7. With the above settings (formulations), we can move on to solving the problem. Next, we can refer to the lecture slides p14~p17 for the full procedure of MDS. Specifically, the equation on lecture slides p17

$ (I - \frac1m \mathbb I \mathbb I^T) \mathbb I a^T (I - \frac1m \mathbb I \mathbb I^T)=0$

can be shown with simple linear algebra. 

8. Lastly, on lecture slides p17, 

$$\tilde G := -\frac12 H(D)^2H \approx \tilde Z^T \tilde Z $$

this expression is the reason why the MDS is an approximation, i.e., the discrepancy between the above two measurements. To make $\frac12 H(D)^2H = \tilde Z^T \tilde Z$, it is required that the embedding vectors $z_i$ be in the Euclidean space, specifically, they need to satisfy the triangular inequality

$$\|z_i - z_k\| + \|z_j - z_k\| \geq \|z_j- z_k\|$$.

Note that $d_{i,j}$ corresponds to $\|z_i, -z_j\|$, if $D$ is not an Euclidean distance matrix, e.g., $d_{i,j} \neq d_{j,i}$, above equation

$$(D)^2 = a \mathbb I^T + \mathbb I a^T - 2 Z^T Z$$

will not hold.

In short about such 'approximation': we are treating the $D$ as Euclidean (which is not in most practical cases) to find the embedding, which is Euclidean. 

The rigorous analysis of the above discrepancy is way beyond the scope of our class.

Comment from User 1144014:
I was going to post this question under HW2 Q3, but realized this may be a better place to ask this question; I was wondering why the centering matrix H and by extension, the centered matrix G tilde cannot be further simplified? 

As I understand it, in H, the (correct me if I'm wrong) portion with 1/m(I I^T) will always simplify to 1/m(I)? Where the I's are square matrices of 1 of size mxm, so what is the significance/implication that it's written out in this way?

  Comment from User 284691:
  There's a great explanation of the centering matrix here: https://en.wikipedia.org/wiki/Centering_matrix

In this notation, I is an identity matrix and the 1's are vectors of all ones. So (1)(1^T) will be a matrix filled with ones, distinct from I (the identity matrix), which has 1's on the diagonal only.

