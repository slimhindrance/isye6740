Thread ID: 5996558
User 134876 (Parent Post) says:
<document version="2.0"><paragraph>Please ask all questions related to HW2 Q3 here.</paragraph><list style="bullet"><list-item><paragraph>There are no runtime requirements for this question, however please keep it reasonable (&lt;10min).</paragraph></list-item><list-item><paragraph>See #130 for additional notes.</paragraph></list-item><list-item><paragraph>PCA package can be used as part of the ISOMAP algorithm. ISOMAP, MDS, and cmdscale (MATLAB) packages are not permitted for this question.</paragraph></list-item></list><paragraph/></document>

Comment from User 568225:
I am confused by the shape of the data in isomap.dat. When I retrieve the images, the shape is (4096, 698). The question states that each datapoint is represented by 4096 features based on luminosity. Based on the shape, this indicates that the rows of the matrix are the features and the columns corresponds to each image. However, the question says that "This vector is stored as a row in the file." Am I missing something obvious? Or do we need to transpose the original data?



  Reply from User 979414:
  I suggest trying to plot image for first face in dataset and it should make things clearer

  Reply from User 307528:
  The eigenvalues should correspond to the covariance matrix derived from 698 samples, not 4096 features.

Comment from User 1127985:
For the first question on Problem3 on ISOMAP, it specifies that we can show the adjacency matrix as an image, but how can we formulate the adjacency matrix if we don't know the tuned epsilon parameter to achieve the most reasonable performance. My assumption is that we have to look at the low-dimensional embedding (Question 2) to determine the performance of epsilon.

So for Question 1 in Problem 3, based on the value of points (5points), are we visualizing the adjacency matrix with a large epsilon where matrix is fully populated? 



  Reply from User 896413:
  No, the adjacency matrix is not meant to be fully connected. Part of your task is to tune your epsilon to produce a meaningful adjacency matrix. If you need a hint on the value range you should try, please see Neepa's office hours. I also highly recommend looking up the paper referenced for this problem for contextual and theoretical background.

Comment from User 1131595:
To clarify the wording in part 1 of this question, if we’re showing an adjacency matrix, then we don’t need to illustrate a few images? That’s only for the scatter plots of the embeddings/principal components for part 2 and 3 where we also show images?

  Reply from User 134876:
  You should display a few images for both methods, whether scatter plot or adjacency matrix. 

Comment from User 1131595:
When performing PCA (on both this question and the food consumption one), I had been scaling the data which I know is common practice and is done in the demo code. However I realized in part 3 of this question, I can replicate the results in the lecture notes only when I don’t scale the data. For the purposes of grading, does it matter whether we scale or not, as long as the implementation is otherwise correct and we accurately interpret our results?

  Reply from User 215365:
  Since all the features (pixel values) are within the same range, scaling is not necessary. Creating the closest reproduction of the plot from the ISOMAP paper and the plot shown on slide 19 of the lecture will be most important.

Comment from User 1232296:
The provided scaffolding file suggests that epsilon is an integer, shouldn't the distance be a float? we are only doing e-ISOMAP not k-ISOMAP, right?

  Reply from User 1232296:
  Unless epsilon here is the number of points we need to check to determine the shortest distance? This part of the paper was a bit unclear, I thought we test against all points and determine the smallest.

If that's the case, then the distance $\epsilon$ should still be a float and is also tunable, right?

  Reply from User 215365:
  We are doing $\epsilon$-ISOMAP and $\epsilon$ will be a float that can be tuned. The Science paper mentions that either $\epsilon$-ISOMAP or $k$-ISOMAP can be used for constructing the neighborhood graph. $\epsilon$ is more of a threshold to determine the neighborhood for each data point as shown on slide 6 of the Nonlinear Dimensionality Reduction slides.

Comment from User 1316216:
I’ve been thinking about ways to pick a good (optimal?) epsilon and the adjacency matrix has a similar feel to the graph laplacian from the first assignment.  Theoretically we could construct a graph laplacian utilizing the adjacency matrix and count the zero eigenvalues to determine the number of disconnected components.  If we search for the smallest epsilon where the graph laplacian has only one zero eigenvalue, is this optimal?

Feels like a cool idea but am I making a bad assumption that connectedness with minimal connections is an optimal way to think of how we represent the manifold for ISOMAP?

  Reply from User 672141:
  Considering this from a graph point of view, epsilon is a threshold to connect nodes. Less connections leads to more isolated nodes and a more sparse graph.

Now, the next part of the algorithm asks for traversing the nodes through the edges. As you are reducing the connections, you are reducing the roads to traverse, therefore unable to compute certain distances. In short, it can cause the algorithm to fail, but your intuition is correct about reducing epsilon.



Comment from User 1128295:
For Q3.3, can we use PCA from a package or do we have to use our own implementation?

  Reply from User 300188:
  yes, you can use PCA from a package. 

Comment from User 1324673:
Part 2 to mentions the "kernel bandwidth". Are we supposed to talk about our epsilon value here?

  Reply from User 300188:
  Will probably update the wording in future semesters to be more accurate, but yes -- talk about how you chose epsilon. 

Comment from User 1229905:
Are there any limitations on the packages we can use to calculate the adjacency matrix?

  Reply from User 300188:
  No, not really for the base assignment. Just don't call an isomap package. 

Comment from User 1497720:
For plotting the faces can we just pick 18 or so random points and plot the faces by the points or does it have to be fixed 18 points? Meaning is it okay if on each run we plot on random 18 points or does reproducible results dictate the same 18 which will be in the report? 

  Reply from User 300188:
  You could just set a seed so the results are reproducible and any analysis you make will be consistent (though it's totally possible  to draw conclusions if the orientation of plots and etc change). 



Comment from User 1498558:
Hi instructors, is this supposed to be inf instead of 0 otherwise? I have difficulty understanding why we should reduce the distance to 0 if it exceeds the epsilon threshold.



  Reply from User 799310:
  I believe the image is correct. Setting it to 0 indicates no edge when the distance exceeds epsilon. Using infinity could suggest an existing edge with a very large weight, which is not what we want. 

Comment from User 1230185:
sklearn PCA acceptable for Q 3.3?

  Reply from User 979414:
  Yes it is acceptable. 

Comment from User 1323477:
Any tips to get started since there's no demo code? I'm pretty lost and I've watched the lecture...unless I'm missing some demo code haha

Comment from User 1229905:
I am trying to figure out how to implement the best epsilon function and I see that the paper defines epsilon as:

but I am having trouble understanding the definition, especially what  r_0. I haven't been able to find any additional information on tuning epsilon. 

  Reply from User 497513:
  It seems to me the formula you cited is about the theoretical analysis and $r_0$ is the assumption about the underlying manifold the data is drawn from.

In our problem, we don't the knowledge about $r_0$. Estimating $r_0$ is very difficult.

In fact, you can choose your threshold with empirical exploration. One clue you can think of is that, 

1) find all pair-wise distance among all data points. 

2) sort the distances, when $\epsilon = 0$, it suggests all data points are isolated without neighbor, when $\epsilon \geq d_{max}$, it suggests all data points are connected, where $d_{max}$ is the largest distance.

3) you can explore the proper value in the range $0 \leq \epsilon \leq d_{max}$



Comment from User 814300:
In this question and in Q2 I am having trouble with the randomness of my answers. When I rerun the script, sometimes my generated plot will flip directions. After troubleshooting, it is because scipy's eigs() function returns the eigenvectors with opposite signs randomly. I tried setting a seed with np.random.seed(6740) which does not work. Reading scipy's documentation for the function, I see a vague statement about setting the initial vector Vo to control randomness, but I am wary of trying that. I noticed in the demo code where this function is used the results seem to be consistent but am unsure why that is.



  Reply from User 497513:
  In this question, you don't need to worry about the flip. It is because the non-uniqueness of the eigenvector.

$$Au = \lambda u, \quad \quad A(-u) = \lambda (-u)$$

both $u$ and $-u$ satisfy the eigenfunction.



Comment from User 1229972:
My understanding is that if we choose a large enough epsilon to connect every point in the dataset, our nearest distance matrix effectively captures euclidean rather than geodesic distance, and the rest of the algorithm essentially performs PCA. When I do this for the faces dataset and compared with sklearn's PCA the results are identical. Does this mean for the PCA implementation in Q3.3 I can simply call my custom isomap function with epsilon = np.inf? I only ask because it seems sklearn is not in the requirements.txt and I dont want to fail the Gradescope autograder because of this dependency.

  Reply from User 979414:
  sklearn is added to requirements.txt file on gradescope. 

Comment from User 896256:
I'm stuck on the first step of forming the adjacency matrix. The number of rows is 698 and each row has 4096 columns representing the luminosity map of each image. The matrix I want to create as a first step is based on:

So I understand I will have a matrix that is 698x698. But if each point has 4096 columns how do I calculate the distance between them? Is this where the suggested shortest_path function comes in? I've tried to infer from the lecture but something is not sinking in. 



  Reply from User 497513:
  Each element in $A$ is the L2 norm of two images. Taking L2 norm of two vectors gives you a scalar. Therefore, you should have 698x698 scalars.

Comment from User 1512055:
In question 1, I plotted the adjacency matrix with my chosen $\epsilon$. To finish answering the question, I'm also supposed to show some of the images on it. The thing is that I don't get exactly what needs to be done... 

Assuming that the value $A_{ij}$ is given by the euclidian distance between datapoints i and j (considering its < $\epsilon$), which image exactly I'm supposed to plot there?



  Reply from User 497513:
  You can simply display the weighted adjacency matrix as a image.

Comment from User 1128222:
On several occasions now I've noticed that numpy isn't producing symmetric matrices when it should be (for instance, a product of three symmetric matrices C = (-1/2) H ((D)^2) H; all of the inputs were verified to be symmetric). In this case, can we just force the symmetry by replacing C with (C + C.T)/2? Here is a github link to the same issue (with np.dot instead of np.linalg.multi_dot): https://github.com/numpy/numpy/issues/12218



  Reply from User 896413:
  Yes, that is permitted. You are aiming for results similar to the ISOMAP paper.

Comment from User 1230185:
I'm still not clear on method for tuning epsilon. I tried few values small to large and outputs looked more like PCA for large values. For moderate value output plot looked exactly like in lecture slides. Can I run a loop over few likely different values of epsilon and looking at heatmap of A and output plot comment on what I feel is good epsilon. 

It's basically visually tuning epsilon. Is this approach acceptable?

  Reply from User 896413:
  Think about what it means to tune epsilon, especially for the adjacency matrix. Here are some tips for tuning, including expected results so you can pick the appropriate epsilon:

https://edstem.org/us/courses/70719/discussion/5996558?comment=13983996

https://edstem.org/us/courses/70719/discussion/5996558?comment=13946072

https://edstem.org/us/courses/70719/discussion/5996558?comment=13925703



Comment from User 962039:
For the images, trying to confirm I'm reading in the data correctly, what direction should the first face be facing? When I initially read it in it's facing up, though if I try reshaping using F order it's another direction. The latter direction makes sense I think, though my Isomap plot seems to be mirrored compared to the slide in the lecture. (e.g. a left facing face is on the right side of the graph, but if the plot was mirrored it'd be as the lecture) Does this matter particularly or is there something I may be missing in reading in the data? 

  Reply from User 896413:
  Either direction is fine, and the mirror will happen randomly. As long as the overall shape is correct, you will get full points. The orientation of the plot and faces does not matter.

Comment from User 1230133:
When I submit order_of_faces.py to the autograder, I get this error. My pca() method is returning an array with shape (698, 2) - which is what it says to do in the scaffolding script - but it looks like Gradescope is telling me it's supposed to have shape (2, 4096)? Which shape is correct?

  Reply from User 979414:
  You may want to plot a single image from the original data source to understand the dataset. (data points vs features)

Comment from User 1512031:
I'm running into an issue where scipy's shortest_path function is returning infinite values when applied to the adjacency matrix A... I'm not quite understanding why this is happening. Is the issue with my adjacency matrix, or am I implementing the shortest_path function incorrectly?



  Reply from User 896413:
  Try tuning your epsilon (higher).

  Reply from User 1519483:
  I came across this issue too and I think it may be because some images are completely isolated when applying a specific ε. Like if we apply a low enough threshold, there are some images that just don't have any neighbours. And if there is no connection between two images, the geodesic distance between them is infinity which MDS cannot handle. Is this correct to say? 

If so, instead of choosing an arbitrary high epsilon value could we do something like replacing all the infinity geodesic distances with the highest non-infinity distance that was found in the graph? 



Comment from User 896256:
Struggling with coming up with a procedure to tune epsilon without resorting to brute force comparisons of the resulting scatter plot with what is shown in the paper. Saw the following snippet in the paper:




Would $r_0$ be the minimum value from the Distance matrix, $D$? Trying to relate manifold, M, to the various constructs mentioned in the lecture slides. 



  Reply from User 213547:
  Please refer to these discussions on how to tune the epsilon

https://edstem.org/us/courses/70719/discussion/5996558?comment=13983996

https://edstem.org/us/courses/70719/discussion/5996558?comment=13946072

https://edstem.org/us/courses/70719/discussion/5996558?comment=13925703

Comment from User 652074:
I would like to double check what pakcage we are allow to use for Q3. 



Are we allow to load scipy.spatial.distance?

  Reply from User 896256:
  I know we can use a PCA package as part of the ISOMAP algorithm we code up. Just can't use an ISOMAP package. 

  Reply from User 213547:
  yes you may. use scipy.spatial.distance

Comment from User 1230103:
Just want to confirm for Q3.3, we don’t have to use the PCA code we wrote for Q2, right? We can use the PCA package from sklearn? Thanks!

  Reply from User 799310:
  Yes, you can use PCA package for 3.3

Comment from User 1519483:
For 3.1, so far I've visualized the adjacency matrix, but not sure what you mean by "illustrating images corresponds to nodes at different parts of the graph". Are you asking us to choose some nodes at random and show what their corresponding image looks like?

  Reply from User 215365:
  A post by Anna explains this well.



  Reply from User 215365:
  Sorry about the permission issue. Yes, you should just choose some random nodes and show the images. The images (three is fine) can go on the diagonal of a heat map, or somewhere on a graph visualization.

Comment from User 1512062:
For 3.2, as part of tuning the epsilon, I noticed this portion on residual variance of Isomap. My idea is to find the residual variance for each epsilon (subject to max epsilon boundary mentioned in https://edstem.org/us/courses/70719/discussion/5996558?comment=13983996 and get the best epsilon with lowest residual variance.

Now, I got a few questions here:
1. Is Dy the euclidean distance matrix obtained from step 1 of the ISOMAP algorithm but not subjected to the epsilon limits? I'm not quite sure what they mean by "Matrix of euclidean distance in low-dimensional embedding recovered by algorithm"

2. What is Dm here and how is it different from Dy? I see https://stats.stackexchange.com/questions/91125/comparing-isomap-residual-variance-to-pca-explained-variance stating that Dm is the "euclidean distance matrix for PCA and the geodesic distance matrix for Isomap". Is this correct? If this is correct, then I want to ask
- What is the matrix we get from PCA to find this euclidean distance matrix? Is this the eigenvectors, or eigenvalues, etc?
- How about the geodesic distance matrix for isomap? Is this the "pairwise shortest distance matrix"?

Just trying to visualise what Dm and Dy this so I can implement the code logic in Python. Thanks team!

  Reply from User 215365:
  1. $D_y$  seems to represent a matrix of distances after the algorithm has embedded the points (after the MDS step for ISOMAP). We don't really measure these distances with the homework question, although they should be similar to the values in the pairwise shortest distance matrix, $D$ (slide 7 of the Nonlinear Dimensionality Reduction lecture). This is the goal of MDS, to preserve the distances as the manifold is unfolded and flattened.

2. I believe $D_m$ is the pairwise shortest distance matrix since it is ISOMAP's estimate of the manifold distances using the graph edge distances (weights). $D_y$ is different and can change depending on how many dimensions you choose to use for embedding (we use two dimensions for this homework question).

For PCA, $D_y$ would just measure the distance between data points ($z^i$) after embedding them (we also do not do this with this homework question)

Figure 2 in the paper shows this residual variance for embedding into different dimensions (between 1 and 10) and this is the context of Note 42. that is highlighted. 

This is an interesting idea for tuning.

Comment from User 814148:
Would love some clear guidance on tuning epsilon for Q3. I understand that we want to keep epsilon reasonably low while preserving as many edges as possible for each node, but this doesn't seem as straight forward as looping through a range for epsilon while setting an minimum number of edges per node. 

  Reply from User 672141:
  It can be as straight forward as you described, depending on your implementation. It's important first to have the ISOMAP algorithm working and plotting the embeddings, then working on the tuning. 

If you try to tune half way as you are working through the algorithm, you will encounter more issues and it will be more difficult to figure out if the root cause is the tuning or the implementation itself.



Comment from User 1325815:


Can any MATLAB users assist on making this plot as shown by Professor Xie in the lecture with the images near their respective points?

  Reply from User 284691:
  You'd probably have to loop over something like the code shown here: https://www.mathworks.com/matlabcentral/answers/311205-how-to-add-images-to-data-points

I used MATLAB for the homework assignments when I took this course, but I didn't add the images directly to the plot. I numbered the points on the plot and added the numbered images near the plot. 

Comment from User 962326:
The plot I get is upside down compared to the ones in the slides. The data I worked on I got from isomap.mat and loaded the values from 'images' which is 4096x698. So, I did a Transapose to get 698x4096. Can you please tell me if this is correct or wrong?



  Reply from User 962232:
  The orientation of the plot doesn't matter since the distances between the points will remain the same. You don't need to transpose the plot, you can leave it as it was.

  Reply from User 1512035:
  The .mat file ends up with sideways images because Matlab reads arrays differently than Python. Still works though. You could try the .dat file instead or flip images for the plot if it bothers you.

  Reply from User 896413:
  Some students have had luck using order = 'F' or 'C' in their reshape (depending on how you read in your data) to get the faces right side up.

Also, please use watermarks if you are posting your plots



Comment from User 1512035:
For Q3.1

I used NetworkX library in Python to plot my nearest neighbor graph but also used entirely native libraries to plot my adjacency matrix visualization. Since NetworkX is not native to Jupyter, can I still include the plots in my writeup but delete the code that generates the plot from my Jupyter file, or should I leave the code, or do something else? I would love to include the plots because they turned out really cool, but generating them without the library is a lot.

  Reply from User 1512040:
  Commenting so I can follow along because I am in the same situation. It takes a non-trivial amount of time to visualize the graph too (my code could probably be more optimized)

  Reply from User 672141:
  Surely, you should include the plots you generated with NetworkX in your report (pdf). If you flip the graph in a certain way you may be able to see the manifold shape Prof X mentions in lecture. 

About the library not being native to Python, you don't need to worry as the TAs will have the necessary packages on their environment to run the code in your Jupyter NB. You can always note it at the top of the notebook with a reference to the library website. 

Comment from User 1128011:
Hi, 

I am having a bit of trouble replicating the plots from lecture for question 3 of HW2. I believe it may be due to how I am reading in the data. When I read in the data, the information is strictly 0s and 1s and results in the following example image:

Can you please advise how I might be able to reconcile this? I am currently reading in the .dat file in Python and converting to "uint8". Thanks!

  Reply from User 962232:
  The data should not be 0 or 1. The pixel data is a float indicating the grayscale value for that pixel. Instead of casting to uint8 you should use float.

  Reply from User 1489130:
  Alternatively, you can multiply the floats Evan mentioned (values between 0 and 1) by 255, which essentially converts them to grayscale (0 to 255).  Afterwards, converting to uint8 and plotting should work.

Comment from User 1080381:
Hello! Just want to confirm, I know we're not allowed to use the ISOMAP package but are we able to use MDS()? 

  Reply from User 300188:
  No. Can't use it. 

Comment from User 307048:
For 3.1, I'm a little confused on what's needed based on the scaffolding. For the get_adjacency_matrix() function, it says to return a "2d numpy array which can directly be used with plt.imshow(...)" But in the 3.1 directions, it says to visualize (1) the adjacency matrix as an image or (2) visualize the graph similar to the lecture slides using graph visualization packages and illustrate a few images corresponding to nodes at different parts of the graph.

I assume we would print this outside of the scaffolding for the report, is that correct? Or should we print it inside the function?

But when it comes to if we want to pick option (1) to visualize the adjacency matrix as an image, is that just a heatmap? Or are we supposed to show mini example images like with the scatterplot in the lecture? Also if we go with (2)... isn't that AFTER ISOMAP is performed? It wouldn't be the adjacency matrix, it would be the final reduced dimension scatterplot, right?

I guess I'm having trouble visualizing what visualizing this adjacency matrix is supposed to look like. Am I overthinking it and is it just a Graph... like a bunch of nodes and connected edges in empty space? 

Thanks! 

  Reply from User 962232:
  It will basically look like a scatter plot with points on it with varying color to show adjacency, so it could be a heatmap, so you can expect that when x=y, there will be a dot since they are equivalent values thus always close together in distance. But also other values that are adjacent will have dots as well. You can still show images by getting the index of that data point and then grabbing the data from your matrix which will be a 1x(number of pixels) vector that you can construct into a HeightxWidth matrix which will represent the grayscale image. 

