Thread ID: 6016871
User 497513 (Parent Post) says:
<document version="2.0"><paragraph>As a supplementary explanation, I'd like to provide some intuition about Multi-Dimensional Scaling (MDS), which is the foundation of the ISOMAP. </paragraph><paragraph>1. The motivation of MDS, to find a low-dimensional representation (so-called embedding), is for visualization purposes. There is a family of MDS algorithms. We focus on the Classic-MDS (cMDS in some literature) in our class. (We will refer to cMDS as MDS in the following.)</paragraph><paragraph>2. We have a set of $m$ data points, $y_1, \cdots, y_m$, where $ y_i \in \mathbb R^d$. We also have a distance measure (dissimilarity function) $d(y_i, y_j)$. Such distance measure is the core interest for the raw feature data in many real-world problems, and it is usually based on prior knowledge (or presumptions). </paragraph><paragraph>3. We want to have a low-dimensional representation of the data (this is an approximation in general). The objective of MDS is to find such embedding $y \rightarrow z: \mathbb R^d \rightarrow \mathbb R^k$, where $k$ is our desired embedding dimension. (In our course example, $ k =2$)</paragraph><paragraph>4. Note that the raw data $y_i$ will not join the subsequent MDS procedure. Only the pair-wise distance $d_{i,j} = d(y_i, y_j)$ are involved. Denote the m-by-m dissimilarity matrix as $D(i,j) = d_{i,j}$.</paragraph><paragraph>5. Based on the given dissimilarity matrix $D$, we move on to finding the embedding $z$. The MDS finds the embedding $z$ by treating the dissimilarity matrix $D$ as Euclidean (Note such treatment is why we say the MDS result is an approximation. I will explain further in the last section.) In this case, we can utilize the equation on lecture slides p14:</paragraph><paragraph>$$d^2_{i,j} = \|z_i - z_j\|^2$$</paragraph><paragraph>In matrix form:</paragraph><paragraph>$$(D)^2 = a \mathbb I^T + \mathbb I a^T - 2 Z^T Z$$</paragraph><paragraph>where $\mathbb I$ is the all-one vector.</paragraph><paragraph>(<bold>keep in mind, $D$ is known, $Z$ is the unknown to be found</bold>)</paragraph><paragraph>6. Now the issue is, that the above equation does not have a unique solution. The reason can be seen quite straightforward with the intuition: $\|z_i - z_j\|$ is the distance between the two embeddings in the space, and if we shift all $z_i$ to an arbitrary location in the embedding space, the distance remains unchanged. Therefore, we need to add an additional constraint by centering the embeddings, thus it can achieve a unique solution. This centering operation corresponds to $H = I - \frac1m \mathbb I \mathbb I^T$ in our lecture slides p16.</paragraph><paragraph>7. With the above settings (formulations), we can move on to solving the problem. Next, we can refer to the lecture slides p14~p17 for the full procedure of MDS. Specifically, the equation on lecture slides p17</paragraph><paragraph>$ (I - \frac1m \mathbb I \mathbb I^T) \mathbb I a^T (I - \frac1m \mathbb I \mathbb I^T)=0$</paragraph><paragraph>can be shown with simple linear algebra. </paragraph><paragraph>8. Lastly, on lecture slides p17, </paragraph><paragraph>$$\tilde G := -\frac12 H(D)^2H \approx \tilde Z^T \tilde Z $$</paragraph><paragraph>this expression is the reason why the MDS is an approximation, i.e., the discrepancy between the above two measurements. To make $\frac12 H(D)^2H = \tilde Z^T \tilde Z$, it is required that the embedding vectors $z_i$ be in the Euclidean space, specifically, they need to satisfy the triangular inequality</paragraph><paragraph>$$\|z_i - z_k\| + \|z_j - z_k\| \geq \|z_j- z_k\|$$.</paragraph><paragraph>Note that $d_{i,j}$ corresponds to $\|z_i, -z_j\|$, if $D$ is not an Euclidean distance matrix, e.g., $d_{i,j} \neq d_{j,i}$, above equation</paragraph><paragraph>$$(D)^2 = a \mathbb I^T + \mathbb I a^T - 2 Z^T Z$$</paragraph><paragraph>will not hold.</paragraph><paragraph>In short about such 'approximation': we are treating the $D$ as Euclidean (which is not in most practical cases) to find the embedding, which is Euclidean. </paragraph><paragraph>The rigorous analysis of the above discrepancy is way beyond the scope of our class. </paragraph></document>

