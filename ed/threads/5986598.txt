Thread ID: 5986598
User 134876 (Parent Post) says:
<document version="2.0"><paragraph>Hello Students,</paragraph><paragraph>As we are all well aware, usage of LLM models including chatGPT, claude, gemini, copilot, etc. have become extremely prevalent in the world of coding. This is fantastic when in the workplace to improve efficiency, but a detriment in a classroom setting as it enables students to skip the learning process and attempt to have AI solve their issues. </paragraph><paragraph>AI has fantastic uses for learning and studying, and we do have an official AI policy in our syllabus, but I wanted to put down our official recommendation for AI usage on homework assignments, as well as remind students that utilizing AI to generate answers, whether it is theory or code based questions, constitutes an academic integrity violation and may result in being referred to OSI for an investigation.</paragraph><paragraph>In general, we strongly recommend not using LLM's/ AI tools at all for your homework assignment, especially in generating sample code or problem assistance. If AI is used, we request that you follow a more comprehensive citation methodology which should include:</paragraph><list style="bullet"><list-item><paragraph>breakdown of the prompts you used (you may provide a link to your AI conversation as well)</paragraph></list-item><list-item><paragraph>what tool/AI model was used</paragraph></list-item><list-item><paragraph>how specifically you utilized the output generated</paragraph></list-item></list><paragraph>Providing this information to us doesn't immediately guarantee your usage is not in violation, but it does allow us to more easily understand whether your usage falls within acceptable guidelines or not. As you can imagine, this can be an extremely gray area, so any questionable assignments get sent to OSI for proper investigation.</paragraph><paragraph>If there are any questions on any of this, please feel free to ask within this thread.</paragraph></document>

